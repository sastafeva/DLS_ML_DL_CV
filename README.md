# Школа глубокого обучения ФПМИ МФТИ
##### Продвинутый поток. 1 полугодие 2021 года.

В этом репозитории выложены домашние задания, выполненные мной в процессе прохождения курса по сверточным нейронным сетям для задач компьютерного зрения.
Архитектуры нейронных сетей реализованы на фреймворке Pytorch.

По каждому заданию мне поставлен высший балл, а за курс получен диплом первой степени.

## Домашние задания

## [1W ML knn](https://github.com/sastafeva/DLS_ML_DL_CV/tree/main/1W_ML_knn)
Введение в машинное обучение.
В домашнем задании предлагалось импортировать несколько методов из библиотеки scikit-learn:
- K Nearest Neighbors
- Logistic Regression
- GridSearchCV

И ответить на вопросы.

## [2W ML Logistic Regression](https://github.com/sastafeva/DLS_ML_DL_CV/tree/main/2W_ML_Logistic_Regression)
Требовалось написать свой класс логистической регрессии с регуляризацией и оптимизацией на основе алгоритма градиентного спуска.

## [3W Kaggle Churn](https://github.com/sastafeva/DLS_ML_DL_CV/blob/main/3W_Kaggle_Churn)
Задание было оформлено в виде соревнования на платформе Kaggle.
Нужно было предсказать отток клиентов по набору некоторых признаков.
Задание состояло из нескольких частей:
- Анализ и предобработка данных
- Применение логистической регрессии с подбором оптимальных параметров
- Применение алгоритма градиентного бустинга с использованием библиотеки Catboost.
- Отправка посылок с предсказаниями на тестовой выборке на Kaggle.

## [6W image classification](https://github.com/sastafeva/DLS_ML_DL_CV/tree/main/6W_image_classification)
По заданию требовалось обучить сверточную нейронную сеть распознавать персонажей из мультсериала Simpsons. Многоклассовая классификация.
Как и в прошлый раз, задание было оформлено в виде соревнования на Kaggle.
В части реализации была предоставлена полная свобода, поэтому я применяла следующее:
- Использовала аугментацию, чтобы разнообразить выборку, т.к. некоторые персонажи были представлены всего парой скриншотов.
- Выбрала модель MobileNetV2, обученную на ImageNet и применила fine-tuning.

В результате модель уверенно предсказала всех персонажей с требуемым по заданию качеством.
Также, я сохранила веса обученной модели для обеспечения воспроизводимости результатов. При необходимости могу отправить ссылку.

## [7W semantic segmentation](https://github.com/sastafeva/DLS_ML_DL_CV/tree/main/7W_semantic_segmentation)
В задании предлагалось реализовать 3 модели сверточных нейронных сетей для сегментации медицинских снимков.
- По статье написать модель SegNet.
- По статье написать модель UNet и ее модифицированную версию
- Обучить каждую модель с 5 разными функциями потерь (итого 15 реализаций)
- Сделать отчет, сравнить качество сегментации и выбрать лучшую комбинацию модель + функция потерь.
- Обеспечить воспроизводимость результатов.

Я сохранила веса обученных моделей на Google Disk. При необходимости могу отправить ссылку.

## [8W autoencoders](https://github.com/sastafeva/DLS_ML_DL_CV/blob/main/8W_autoencoders/)

По заданию нужно было написать несколько моделей автоэнкодеров и выполнить несколько заданий. Я сделала немного больше, чем требовалось, а также выполнила оба бонусных задания (без оценки).

- Autoencoder. 
    -  Обучила на лицах людей
    -  Научилась восстанавливать лица из случайного шума.
    -  Научилась делать лица радостными и надевать им очки.
- Variational Autoencoder
    - Обучила на MNIST
    - Научилась генерировать изображения случайного шума из гауссовского распределения.
- Conditional Variational Autoencoder
    - Обучила на MNIST
    - Научилась генерировать конкретное число
- Bonus1: Denoising
    -  Обучила автоэнкодер удалять шум с фотографий лиц.
- Bonus2: Image Retrieval
    - Научилась находить изображения похожих людей с помощью латентного вектора вариационного автоэнкодера.

Я сохранила веса обученных моделей на Google Disk. При необходимости могу отправить ссылку.

## [10W GAN](https://github.com/sastafeva/DLS_ML_DL_CV/tree/main/10W_GAN)

В задании предлагалось реализовать архитектуру генеративно-состязательной сети для генерации лиц людей, и выполнить несколько дополнительных заданий.
Я выполнила задание в 2-х вариантах:
 - Обучила GAN для генерации изображений размером [256 х 256](https://github.com/sastafeva/DLS_ML_DL_CV/blob/main/10W_GAN/10W_%5Bhw%2Cadv%5D_GAN_image_256.ipynb)
 - Обучила GAN для генерации изображений размером [128 х 128](https://github.com/sastafeva/DLS_ML_DL_CV/blob/main/10W_GAN/10W_%5Bhw%2Cadv%5Dg_GAN_image_128.ipynb)

Я пробовала довольно много вариантов, чтобы улучшить результаты:
- Пробовала разную глубину сверточных слоев для генератора и дискриминатора.
- Эксперементировала с различным количеством линейных слоев.
- Применяла разные функции активации с разными гиперпараметрами.
- Пробовала убирать нормализацию и денормализацию с разными функциями активации на выходе из генератора.
- Использовала MSELoss для генератора и дискриминатора, и только для генератора.
- Меняла шаг градиентного спуска (с самого начала, в процессе обучения с помощью lr_scheduler, с 100, 150, 200, 250 эпохи).
- Зашумляла метки классов различными коэффициентами.
- Выбирала разные оптимизаторы для генератора и дискриминатора, и эксперементировала с их гиперпараметрами.
- Пробовала несимметричные генератор и дискриминатор (с большим количеством слоев то в одной, то в другой модели).
- Выбирала разный шаг градиентного спуска для оптимизатора генератора и оптимизатора дискриминатора (при одном и том же оптимизаторе).
- Учила разное количество эпох (до 500).
- Пробовала разные входящие размеры изображений (больше всего экспериментов было с размерами 256х256 и 128х128).
- Брала разные размеры латента и разные размеры батчей и т.д. 

Результаты получались разными, но всегда неудовлетворительными. На мой взгляд второй вариант (128 х 128) выглядит лучше.

Я сохранила веса обученных моделей, и промежуточные результаты генерации на Google Disk. При необходимости могу отправить ссылку.

## [11W project object detection](https://github.com/sastafeva/DLS_ML_DL_CV/tree/main/11W_%5Bproject%5D_object_detection)

Студентам предлагалось на выбор несколько тем для финального проекта, я выбрала детекцию изображений.

Я решала задачу детекции на датасете с фотографиями со строительной площадки.
Датасет был загружен с платформы [Kaggle](https://www.kaggle.com/andrewmvd/hard-hat-detection).
Исходная разметка включала bounding boxes людей, головы в каске и головы без каски. Разметку людей пришлось исключить, т.к. она была выполнена не для всех изображений и модель плохо справлялась с задачей.
Проект был выполнен с использованием фреймворка [MMDetection](https://github.com/open-mmlab/mmdetection)
Я проанализировала несколько обученных моделей из библиотеки MMDetection и выбрала CenterNet, которая имеет существенное преимущество перед остальными моделями - ее веса занимают очень мало памяти, а значит ее легко можно будет адаптировать для задачи видео-детекции.

После обучения на выбранном датасете модель уверенно определяла есть каска на человеке или нет, не смотря на то, что разметка датасета была неполной.

Результаты работы я сохранила на Google Disk. При необходимости могу отправить ссылку.
